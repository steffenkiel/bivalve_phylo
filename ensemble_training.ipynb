{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# TRAINING OF THREE CNNS WITH RESNET50_V2 ARCHITECTURE, ON THE SAME SET OF IMAGES \n",
    "\n",
    "from tensorflow.python.keras.applications.resnet_v2 import preprocess_input, ResNet50V2\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.python.keras.models import Sequential, save_model, load_model, optimizers\n",
    "from tensorflow.python.keras.layers import Activation, Dense, Flatten, GlobalAveragePooling2D \n",
    "from tensorflow.keras.optimizers import SGD \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os, pathlib\n",
    "\n",
    "# load ResNet50_V2\n",
    "resnet = ResNet50V2(include_top=False, pooling=\"avg\", weights='imagenet')\n",
    "\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Built with CUDA:\",tf.test.is_built_with_cuda())\n",
    "print(\"Tensorflow version:\",tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET FILE PATHS AND VARIABLES AND DEFINE FUNCTIONS\n",
    "\n",
    "# directory with images and for output except weights\n",
    "base_path = \"working_directory/\"\n",
    "\n",
    "# the images for each CNN need to be named and sorted as follows:\\n\"\n",
    "#  \"working_directory/IMAGES_by_family/\"\n",
    "#  \"working_directory/IMAGES_by_family/train/\"\n",
    "#  \"working_directory/IMAGES_by_family/train/FamilyName_1/\"   <- replace \"FamilyName_1\" by the actual family name\n",
    "#  \"working_directory/IMAGES_by_family/train/FamilyName_1/img1.jpg\n",
    "#  \"working_directory/IMAGES_by_family/train/FamilyName_1/img2.jpg\n",
    "#  \"working_directory/IMAGES_by_family/train/FamilyName_1/img3.jpg\n",
    "\n",
    "#  \"working_directory/IMAGES_by_family/\n",
    "#  \"working_directory/IMAGES_by_family/train/\n",
    "#  \"working_directory/IMAGES_by_family/train/FamilyName_2/\" <- replace \"FamilyName_2\" by the next family name\n",
    "#  \"working_directory/IMAGES_by_family/train/FamilyName_2/img1.jpg\"\n",
    "#  \"working_directory/IMAGES_by_family/train/FamilyName_2/img2.jpg\"\n",
    "#  \"working_directory/IMAGES_by_family/train/FamilyName_2/img3.jpg\"\n",
    "\n",
    "#  the same structure is needed for:\"\n",
    "#  \"working_directory/IMAGES_by_family/validation/\"\n",
    "#  \"working_directory/IMAGES_by_family/test/\"\n",
    "\n",
    "# the same as above is also needed for 'order' and 'clade':\n",
    "#  \"working_directory/IMAGES_by_order/\"\n",
    "#  \"working_directory/IMAGES_by_order/train/OrderName_1\" etc.\n",
    "#  \"working_directory/IMAGES_by_clade/\"\n",
    "#  \"working_directory/IMAGES_by_clade/train/CladeName_1\" etc.\n",
    "\n",
    "# directory for the weights (specify directory other than 'base_path' if desired)\n",
    "for_weights = base_path\n",
    "\n",
    "# the taxonomic level and their hyperparameters\n",
    "tls = [\"family\", \"order\", \"clade\"]\n",
    "lrs = [0.01, 0.1, 0.01]\n",
    "dcs = [0.001, 0.01, 0.001]\n",
    "mms = [0.9, 0, 0.5]\n",
    "\n",
    "# other variables\n",
    "batch_size = 16\n",
    "image_size = 224\n",
    "no_epochs = 600\n",
    "\n",
    "# callback\n",
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, directory):\n",
    "        super().__init__()\n",
    "        self.directory = directory\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # save model weight\n",
    "        self.model.save_weights(self.directory + \"weights_epoch_{:03d}.hdf5\".format(epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE FULL TRAINING PROGRAM\n",
    "\n",
    "for taxonomic_level, lr, decay, momentum in zip(tls, lrs, dcs, mms):\n",
    "    \n",
    "    # create directory for weights\n",
    "    weights_filepath = for_weights + \"weights_\" + taxonomic_level + \"/\"\n",
    "    os.mkdir(weights_filepath)\n",
    "    \n",
    "    #_________________________________________\n",
    "    # EXAMINE IMAGES AND CLASS NAMES\n",
    "    print(\"Assessing images for\", taxonomic_level)\n",
    "    \n",
    "    # path to directory with images\n",
    "    data_path = base_path + 'IMAGES_by_' + taxonomic_level + '/'\n",
    "\n",
    "    # the file to write class names into\n",
    "    classnames_filename = base_path + \"classnames_\" + taxonomic_level + \".txt\"\n",
    "    \n",
    "    # examine TRAIN images\n",
    "    train_path = data_path + 'train'\n",
    "    train_dir = pathlib.Path(train_path)\n",
    "    train_image_count = len(list(pathlib.Path(train_dir).glob('*/*.jpg')))\n",
    "    print('Found',train_image_count,'TRAINING images.')\n",
    "\n",
    "    # examine VALIDATION images\n",
    "    val_path = data_path + 'validation'\n",
    "    val_dir = pathlib.Path(val_path)\n",
    "    val_image_count = len(list(pathlib.Path(val_dir).glob('*/*.jpg')))\n",
    "    print('Found',val_image_count,'VALIDATION images.')\n",
    "\n",
    "    # examine TEST images\n",
    "    test_path = data_path + 'test'\n",
    "    test_dir = pathlib.Path(test_path)\n",
    "    test_image_count = len(list(pathlib.Path(test_dir).glob('*/*.jpg')))\n",
    "    print('Found',test_image_count,'TEST images.')\n",
    "\n",
    "    # get class names\n",
    "    class_names = np.array([item.name for item in train_dir.glob('*')])\n",
    "    num_classes = len(class_names)\n",
    "    print('Found',num_classes,'CLASSES:',class_names)\n",
    "\n",
    "    # create bivalve class_name decoder\n",
    "    class_name_list=np.ndarray.tolist(class_names)\n",
    "    keys=range(len(class_name_list))\n",
    "    decode_bivalves=dict(zip(keys, class_name_list))\n",
    "\n",
    "    # write the class_names into a file\n",
    "    with open(classnames_filename, \"w\") as outfile:\n",
    "        outfile.write(\"\\n\".join(class_name_list))\n",
    "\n",
    "    print(f\"\\nSaved class names and created decoder for\", taxonomic_level + \".\\n\")\n",
    "\n",
    "    #_________________________________________\n",
    "    # SET UP DATA GENERATORS\n",
    "    # train data generator\n",
    "    data_generator_train = ImageDataGenerator(    \n",
    "        preprocessing_function=preprocess_input,\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.2,\n",
    "        channel_shift_range=0.3)  #, horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "    train_generator = data_generator_train.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    # validation data generator\n",
    "    data_generator_val = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "    validation_generator = data_generator_val.flow_from_directory(\n",
    "        val_path,\n",
    "        target_size=(image_size, image_size),\n",
    "        class_mode='categorical')\n",
    "    \n",
    "    # test data generator\n",
    "    data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "    test_data_loader = data_generator.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=test_image_count,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    # load test images\n",
    "    print(f'\\nNow loading TEST images with img_size = {image_size}...')\n",
    "    test_images, test_labels = next(test_data_loader)\n",
    "    test_images = test_images.astype('float32')\n",
    "    print('...done.')\n",
    "\n",
    "    #_____________________________________________________________________________________\n",
    "    # CALCULATE CLASS WEIGHTS based on the number of images in each subfolder in TRAIN\n",
    "    # get number of images in each folder of TRAIN (=train images per class)\n",
    "    images_per_dir = [len(files) for r, d, files in os.walk(train_path)]\n",
    "    images_per_dir.pop(0)           # remove first element (= the main directory)\n",
    "    no_dirs = len(images_per_dir)   # should be the same as num_classes\n",
    "    total_images = sum(images_per_dir)\n",
    "    weights_per_dir = [total_images/x for x in images_per_dir]\n",
    "\n",
    "    # put them into class_weights dictionary\n",
    "    class_weights = dict(zip(range(no_dirs), weights_per_dir))\n",
    "    print(f'Calculated class weights for {no_dirs} classes based on {total_images} images in TRAIN.\\n')\n",
    "\n",
    "    #_________________________________________\n",
    "    # COMPILE MODEL\n",
    "    # re-create resnet's output layer with 'num_classes'\n",
    "    for layer in resnet.layers:\n",
    "        layer.trainable=False\n",
    "\n",
    "    logits = Dense(num_classes)(resnet.layers[-1].output)\n",
    "    output = Activation('softmax')(logits)\n",
    "    bivalve_model = Model(resnet.input, output)\n",
    "\n",
    "    # create optimizer and compile model\n",
    "    opt=SGD(lr=lr, decay=decay, momentum=momentum)\n",
    "    bivalve_model.compile(optimizer=opt, loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    print(taxonomic_level, \"model compiled.\")\n",
    "    \n",
    "    #_________________________________________\n",
    "    # TRAINING\n",
    "    # print training parameters\n",
    "    print(f'\\nNow training for {no_epochs} epochs, with image size = {image_size}, batch size = {batch_size},')\n",
    "    print(f'  lr = {lr}, decay = {decay} and momentum = {momentum}\\n')\n",
    "\n",
    "    # Fit Model\n",
    "    history = bivalve_model.fit(\n",
    "        train_generator,\n",
    "        epochs=no_epochs,\n",
    "        validation_data=validation_generator,\n",
    "        class_weight=class_weights,\n",
    "        callbacks=[CustomCallback(\n",
    "            directory=weights_filepath)])\n",
    "\n",
    "    # print results of training\n",
    "    print(f\"\\n----------------------------------------------------------------------\")\n",
    "    print(f\"Training results:\")\n",
    "    print(' Mean val_accuracy:', np.mean(history.history['val_accuracy']))\n",
    "    print(' Maximum val_accuracy:',max(history.history['val_accuracy']))\n",
    "\n",
    "    # convert the history.history dict to a pandas DataFrame:     \n",
    "    hist_df = pd.DataFrame(history.history) \n",
    "\n",
    "    # and save to csv:\n",
    "    with open(base_path + taxonomic_level + '_history.csv', mode='w') as f:\n",
    "        hist_df.to_csv(f, index=False)\n",
    "\n",
    "    # print scores on TEST images\n",
    "    scores = bivalve_model.evaluate(test_images, test_labels, batch_size = test_image_count, verbose=0)\n",
    "    print(f' Scores for {test_image_count} test images: {bivalve_model.metrics_names[0]} of {\"{:.2f}\".format(scores[0])}; {bivalve_model.metrics_names[1]} of {\"{:.2f}\".format(scores[1]*100)}%')\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "\n",
    "    #_________________________________________\n",
    "    # PLOT TRAINING HISTORY\n",
    "    # Plot training & validation accuracy values\n",
    "    print(\"Training history:\")\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validate'], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validate'], loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
